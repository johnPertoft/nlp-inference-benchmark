{
    "name": "nlp-inference-benchmark",
    "context": ".",
    "dockerFile": "Dockerfile",
    "runArgs": [
        "--gpus=all",
        "--ipc=host"
    ],
    "mounts": [
        "source=/tmp,target=/tmp,type=bind,consistency=cached"
    ],
    "extensions": [
        "ms-python.python",
        "ms-python.vscode-pylance",
        "eamodio.gitlens"
    ],
    "features": {
        "ghcr.io/devcontainers/features/docker-from-docker:1": {
            "version": "latest"
        }
    },
    "settings": {
        "terminal.integrated.defaultProfile.linux": "zsh",
        "python.pythonPath": "/opt/conda/bin/python",
        "python.formatting.provider": "black",
        "python.formatting.blackPath": "/usr/local/py-utils/bin/black",
        "python.linting.enabled": true,
        "python.linting.flake8Enabled": true,
        "python.linting.flake8Path": "/usr/local/py-utils/bin/flake8",
        "python.linting.mypyEnabled": true,
        "python.linting.mypyPath": "/usr/local/py-utils/bin/mypy",
        "editor.wordBasedCompletionInComments": false
    }
    // "postAttachCommand": [
    //     "pre-commit", "install"
    // ]
}
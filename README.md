# nlp-inference-benchmark
This repo holds benchmarks for some deep learning inference frameworks for our specific workload.

## TODO
- Define some delimitations, e.g. only running on 3080, only using T5 etc
- Define some common output report format
